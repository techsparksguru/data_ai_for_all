{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49fa13cb-be52-404a-82ab-cdfb676a7898",
   "metadata": {
    "tags": []
   },
   "source": [
    "# References\n",
    "- https://python.langchain.com/docs/modules/chains/popular/summarize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9459093b-30a2-499c-ba1e-4940ead92573",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=10, micro=12, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b091b9b-c02d-4d44-b437-ccfcdcbab1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install langchain==0.0.242\n",
    "!pip3 install chromadb==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940e9ab1-22b1-4098-b90a-5689dce50e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "SCRAPE_URL = \"https://medium.com/@symmetrics_hr/the-m%CC%B6o%CC%B6n%CC%B6k%CC%B6-immigrant-who-s%CC%B6o%CC%B6l%CC%B6d%CC%B6-bought-his-ferrari-e7be20c4d891\"\n",
    "DEFAULT_QUESTION = \"What is H1b?\"\n",
    "SAMPLE_PDF_DOCUMENT = \"Tech_Hubs_NOFO.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d525742d-b3cf-455b-bd52-f53155f85973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The MĚ¶oĚ¶nĚ¶kĚ¶ Immigrant Who SĚ¶oĚ¶lĚ¶dĚ¶ Bought His Ferrari | by SparkIQ Tech | MediumThe MĚ¶oĚ¶nĚ¶kĚ¶ Immigrant Who SĚ¶oĚ¶lĚ¶dĚ¶ Bought His FerrariSometimes the last mile action you take in your journey decides whether you fulfil your American Dream !SparkIQ TechÂ·Follow7 min readÂ·Jan 29--ListenShareBackgroundThe Monk Who Sold His Ferrari tells the extraordinary story of Julian Mantle, a lawyer forced to confront the spiritual crisis of his out-of-balance (lavish and rich) life, and the',\n",
       " 'subsequent wisdom that he gains on a life-changing odyssey that enables him to create a life of passion, purpose and peace.While spirituality is in its place and a very personal realisation, for most of us material things (some are small, some medium and some large) is what drives us to live this life (and ushers hope too, unless you are one of those naturally born spiritual ones). If you are relatively younger, chances are you have dreams of acquiring a certain thing in your life. For',\n",
       " 'automobile aficionados, owning the brand of car that you dreamed since childhood can be the biggest achievement of life (until then).This article is about Venkat^[1], a Google Engineer who wished to buy his Ferrari before he reaches the age of 40H1b VisaIf you work in US tech sector, you donâ€™t need introduction to H1b. It is one of the most sought after visa (among many others) that is given to a worker with high skills (as defined by US government). Basically the united states government',\n",
       " 'instated the high skilled program in late 90â€™s (and formalised by 2000) as it realised that owning the apex in creating, maintaining and disseminating technologies will ensure being the only superpower in the world â€” Attract the best and the brightest across the world and enable them to build and maintain the greatest products and services , while owning the IP with full authority and control.An H1b Immigrant â€” Ferrari DreamVenkat was born and brought up in an Indian lower-middle class',\n",
       " 'family in the early 80â€™s. His mother was a homemaker and his father worked as a site supervisor under a real estate contractor. The average income per month was 5000 INR which barely met the familyâ€™s expenses. Venkat went to a government school and by class 10, his parents realised that Venkat was an extremely hard-working, intelligent and smart kid. He was not only the topper in academics, but aced in extra-curricular activities like winning quiz competitions, chess and so on.Venkatâ€™s',\n",
       " 'father had a bicycle he used to commute to work, and Venkat got his first bicycle to ride at the end of class 12. He used to watch his other classmates with motor bikes and always dreamt of one when he could earn on his own. By the time he graduated from his mechanical engineering, he had a belly fire and confidence to be able to uplift his entire family out of poverty, and planned for next things in life (like get married , own a home etc.). His love to own a Ferrari developed during his',\n",
       " 'engineering years â€” spending hours printing Ferrari labels and arranging them on his walls, showing off his Ferrari collectibles to his friends and watching every Ferrari race without fail.Any financial decision he made, was towards owning a Ferrari at some point in his lifeBy 2017 Venkat worked in Indian IT industry for 4 years. He had a home, wife and 2 kids, however he realised that he was in this never ending loop of going to office, paying bills/mortgage, coming home tired after wading',\n",
       " 'through traffic and then the day repeats. Weekends were pretty much kids time and weekdays â€” were doing kids projects. His Ferrari dream seemed very far away now.Luckily his company applied for an H1b application for him as the client he worked for, wanted his presence in the US. His hope to own a Ferrari got kindled again !Move to USAVenkatâ€™s application got picked in H1b lottery in 2019 and he moved to the US soon after. To fund his move, he sold his assets in India and his new life',\n",
       " 'started in the bay area during the COVID era. He was quite happy that he was making $100k / annum. After 2 years of working, family needs started coming up again. He started sending his kids to private school as they were not US citizens yet and that costed him dearly. Then the need from home came up again. He bought a single family home that costed him around 1 million (a decent small family home around bay area costs that much) and took a 30 year mortgage.One day he started calculating his',\n",
       " 'monthly expenses and he realised that it was close to $10k (even though they compromised on many needs and wants). By this time his salary was around $180k and after taxes he was getting around ~12k in hand. So his savings per month was ~2k. He made some stock market investments and had around 150k savings.Doing some math, he realised that he would have to wait at least 30â€“40 years (to buy the lowest end Ferrari â€” 227k) and that would pretty much mean end-of-life. He mulled over all',\n",
       " 'possible options and doors were closed. He obviously cannot sacrifice needs for wants (and his dream of owning Ferrari almost died).Change Jobs â€” Negotiate with ConfidenceOne day over drinks with a group of friends, one of them suggested he should change his job if he really wants to fulfil his dream. He referred him to the article Data-Driven Career Coaching and pointed to the section that explained how John made an additional $40k just because he was able to access the right data during',\n",
       " 'salary negotiation.Venkat reached out to Symmetrics team for free coaching. The team evaluated his existing offer (job title, company , location) and used the database to show him that he did not negotiate well on the offer. In fact he was leaving at least $50k on the table.The $50k is the margin that Venkat needed to fulfil his dream. He got the data in the same format as that of John (sample shown below)Venkat went back to the employer and showed the dataThe same employer for the same job',\n",
       " 'title paid at least $50k extra for 50 more candidates during the same yearVenkat requested the employer to pay him the same and show good faithThats it !The HR team went back and revised the offer with an additional $40k. They knew that the data from Symmetrics is employer-submitted and government verified (there is hardly any room to deny the data â€” unlike user-submitted data found on random Google links)Did past salary matter ?There are some employers who ask your previous salary history',\n",
       " 'even before you interview. It is a personal choice whether you want to specify (in fact in some states, it is illegal to ask previous salary history). In the above case, Venkat did NOT want to give away his previous salary details UNTIL he knew the work load, his responsibilities and the team he is going to work with. Most of those fears were allayed during the interview process (as he learnt about the humans he was going to collaborate with)Any other factors ?Yes absolutely. There were some',\n",
       " 'subjective inferences made by the career coach for Venkat â€” especially his depth and breadth of hard skills, soft skills like communication, collaboration, amicability etc. It is the cumulative assessment using data and experience of the coach, that helped Venkat. The coach would NOT have been convincing enough to Venkat (neither Venkat would have during his negotiation of the offer) without Data!ConclusionIf Venkat was not confident of his skills, obviously no amount of data can help. In',\n",
       " 'this case, Venkat knew he was relatively smart and hardworking employee. He just did not want to leave money on the table. He made at least additional $40k-$50k just because he signed up for coachingNext time you seek coaching or get coached , do ask for Data Driven coaching !Platforms like Symmetrics are championing open wage metrics & Data Driven coaching at scale. Sign up for a coaching session OR Register as a coachRead more detailsIf you are self-driven, feel free to explore the data on',\n",
       " 'your ownMore ArticlesWhat Most of Us Still Get Wrong About LayoffsState of High Skilled Jobs â€” 2022 FINALState of High Skilled Jobs â€” 2022 Q3State of High Skilled Jobs â€” 2022 Q2State of High Skilled Jobs â€” US West Region â€” 2022 Q2Data Driven Career CoachingAmazon 350k base salary is smoke & mirrorsHow to Analyze and Negotiate your Salary â€” 101How to deal with Ghosting â€” as an employerAverage wage can deceive youDo you know your Jobâ€™s net worth ?Things the smart do BEFORE',\n",
       " 'accepting a new offerThe Great Big Resignation and now this!To Each his domainRecruitingFerrariTechTechnologyTechnews----FollowWritten by SparkIQ Tech6 FollowersHR , STAFFING & RECRUITINGFollowMore from SparkIQ TechSparkIQ TechState of High Skilled Jobs 2023 Q2â€Šâ€”â€ŠHires and FiresInteresting that companies that laid off were also the companies that hired during the same time period. As we forecasted last quarterâ€¦6 min readÂ·May 24--SparkIQ TechState of High Skilled Jobsâ€Šâ€”â€Š2023',\n",
       " 'Q1Interesting that companies that laid off were also the companies that hired during same time periodÂ\\xa0:)6 min readÂ·Feb 17--SparkIQ TechWhat Most Of Us Still Get Wrong About LayoffsIf you are a JOBSEEKER, hone your skills now to be ready for Q1 2023 hiring season. If you are an EMPLOYER, donâ€™t be greedy to use marketâ€¦8 min readÂ·Dec 23, 2022--SparkIQ TechState of High Skilled Jobsâ€Šâ€”â€Š2022 FINALBackground4 min readÂ·Dec 15, 2022--See all from SparkIQ TechRecommended from',\n",
       " \"MediumUnbecoming10 Seconds That Ended My 20 Year MarriageItâ€™s August in Northern Virginia, hot and humid. I still havenâ€™t showered from my morning trail run. Iâ€™m wearing my stay-at-home momâ€¦Â·4 min readÂ·Feb 16, 2022--850Kristen WaltersinAdventures In AI5 Ways Iâ€™m Using AI to Make Money in 2023These doubled my income last yearÂ·9 min readÂ·6 days ago--262ListsApple's Vision Pro7 storiesÂ·9 savesChatGPT prompts 22 storiesÂ·150 savesAI Regulation6 storiesÂ·42 savesChatGPT21 storiesÂ·60\",\n",
       " 'savesThe PyCoachinArtificial CornerYouâ€™re Using ChatGPT Wrong! Hereâ€™s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering.Â·7 min readÂ·Mar 17--522Jari RoomerinBetter HumansHow I Eliminated Procrastination From My Life (Using Neuroscience)Keep this part of the brain in optimal condition if you want to stop procrastinating.Â·6 min readÂ·Jun 22--145Ignacio de GregorioMicrosoft Just Showed us the Future of ChatGPT with LongNetLetâ€™s talk about BillionsÂ·8 min',\n",
       " 'readÂ·4 days ago--26Zulie RaneinThe StartupIf You Want to Be a Creator, Delete All (But Two) Social Media PlatformsIn October 2022, during the whole Elon Musk debacle, I finally deleted Twitter from my phone. Around the same time, I also logged out ofâ€¦Â·8 min readÂ·Apr 19--795See more recommendationsHelpStatusWritersBlogCareersPrivacyTermsAboutText to speechTeams']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document loader\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(SCRAPE_URL)\n",
    "data = loader.load()\n",
    "\n",
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "# Since FAISS requires splits from text and not Lang Document type, we do the below\n",
    "all_splits = text_splitter.split_text(text=data[0].page_content)\n",
    "all_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee194e-f701-4a5b-972c-10bdcf5f5c55",
   "metadata": {},
   "source": [
    "## MapReduce chain type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a3995e4-82ef-40c6-86f1-4b80f1c2a348",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 3200\n",
      "llama_model_load_internal: n_mult     = 240\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 26\n",
      "llama_model_load_internal: n_rot      = 100\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 8640\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 3B\n",
      "llama_model_load_internal: ggml ctx size =    0.06 MB\n",
      "llama_model_load_internal: mem required  = 2862.72 MB (+  682.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  650.00 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n\\nThe story of a lawyer who sold his Ferrari to find redemption through spirituality.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms import GPT4All\n",
    "\n",
    "llm = GPT4All(model=\"/home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\",max_tokens=2048)\n",
    "chain = load_summarize_chain(llm=llm, chain_type=\"map_reduce\")\n",
    "\n",
    "docs = [Document(page_content=t) for t in all_splits[:3]]\n",
    "\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf809a-4bbb-44ae-a7c5-82e28d93fa44",
   "metadata": {},
   "source": [
    "## Stuff Chain Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be848cd1-adb7-4727-9d99-f5cfc4cd1b29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The article talks about a man named Venkat who worked as a Google Engineer and wished to buy his Ferrari before he turned 40. He applied for H1b visa, which is a highly sought-after visa in the US tech sector. The article describes how he faced many challenges but eventually succeeded in getting the visa.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm=llm, chain_type=\"stuff\")\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d823a1-35ae-4722-abcd-2d90504e96c7",
   "metadata": {},
   "source": [
    "# Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75934309-a76d-4c31-bb64-f1de324c70d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" L'immigrato tedesco che ha acquistato la Ferrari 599 GTB Fiorano, racconta la storia di una vita cambiata e l'avventura spirituale che lo hanno portato ad un'existential crisis e all'ascensione spiritica.�� un'esperienza personale e personalissima, ma è stato anche questa la storia di una persona che ha capito come sia importante per la vita avere un'attività passionaria e divertente, e non solo una vita di lavoro.�� un'esperienza che\\n\\nè molto utile per chiunque abbia paura di non poter fare quello che desidera o che sia in equilibrio spirituale. La storia è anche un'esempio di come una persona, dopo essere andata a grandi distanze dal suo cammino spirituale, possa tornare indietro e capire cosa significa per la vita seguirgli.�� stato un'avventura\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "{text}\n",
    "CONCISE SUMMARY IN ITALIAN:\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "chain = load_summarize_chain(llm=llm, chain_type=\"stuff\", prompt=PROMPT)\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9a1ed6f-d7f4-4d31-8512-71392fc70571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': [' The M����o����n����k���� Immigrant Who S����o����l����d���� Bought His Ferrari | by SparkIQ Tech | MediumThe Monk Who Sold His Ferrari tells the story of a lawyer who was forced to confront his spiritual crisis and out-of-balance life, and how he found redemption through selling his beloved Ferrari.',\n",
       "  ' \\n\\nThe story follows the journey of an individual who embarks on a life-changing odyssey that leads to personal growth and fulfillment. The protagonist realizes the importance of spirituality in his life, but also learns that material things are what drives him to live this life and hope. The story highlights the significance of balance between these two aspects of life.',\n",
       "  ' \\n\\nThe article talks about a person named Venkat who had always dreamed of owning a Ferrari. He finally achieved his dream when he purchased the car he had been dreaming about since childhood. However, this was not enough for him and he also applied for an H1B visa to work in the US tech sector. The article highlights how difficult it is to get an H1B visa and how important it is for people working in the US tech sector.'],\n",
       " 'output_text': ' \\n\\nThe story of a lawyer who sold his Ferrari to find redemption through spirituality.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm=llm, \n",
    "                             chain_type=\"map_reduce\", \n",
    "                             return_intermediate_steps=True)\n",
    "chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb020a-25a7-4b07-907f-786ae55c33f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Custom MapReduce Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a19a089-6ce4-4b17-a3a0-f467d8ecb401",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 3200\n",
      "llama_model_load_internal: n_mult     = 240\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 26\n",
      "llama_model_load_internal: n_rot      = 100\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 8640\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 3B\n",
      "llama_model_load_internal: ggml ctx size =    0.06 MB\n",
      "llama_model_load_internal: mem required  = 2862.72 MB (+  682.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  650.00 MB\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain,ReduceDocumentsChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "llm = GPT4All(model=\"/home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\",max_tokens=2048)\n",
    "\n",
    "map_template_string = \"\"\"Give the following article , generate a summary of the article and mention the source of article\n",
    "Code:\n",
    "{article}\n",
    "\n",
    "Return the summary in the following format:\n",
    "summary: summary text\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "reduce_template_string = \"\"\"Given the following summary text, answer the following question\n",
    "{summary_text}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Prompt to use in map and reduce stages \n",
    "MAP_PROMPT = PromptTemplate(input_variables=[\"article\"], template=map_template_string)\n",
    "REDUCE_PROMPT = PromptTemplate(input_variables=[\"summary_text\", \"question\"], template=reduce_template_string)\n",
    "\n",
    "# LLM to use in map and reduce stages \n",
    "# llm = OpenAI()\n",
    "map_llm_chain = LLMChain(llm=llm, prompt=MAP_PROMPT)\n",
    "reduce_llm_chain = LLMChain(llm=llm, prompt=REDUCE_PROMPT)\n",
    "\n",
    "# Takes a list of documents and combines them into a single string\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_llm_chain,\n",
    "    document_variable_name=\"summary_text\",\n",
    ")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents \n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "        # This is final chain that is called.\n",
    "        combine_documents_chain=combine_documents_chain,\n",
    "        # If documents exceed context for `combine_documents_chain`\n",
    "        collapse_documents_chain=combine_documents_chain,\n",
    "        # The maximum number of tokens to group documents into\n",
    "        token_max=3000)\n",
    "\n",
    "# Combining documents by mapping a chain over them, then combining results with reduce chain\n",
    "combine_documents = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_llm_chain,\n",
    "     # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"article\",\n",
    ")\n",
    "\n",
    "\n",
    "map_reduce = MapReduceChain(\n",
    "    combine_documents_chain=combine_documents,\n",
    "    text_splitter=CharacterTextSplitter(chunk_size=500, chunk_overlap=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dccb7c23-9727-4a67-b0a2-09a8ab863f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLaMA ERROR: The prompt is 2887 tokens and the context window is 2048!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The profession mentioned in the article is \"Journalist\".'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(SCRAPE_URL)\n",
    "data = loader.load()\n",
    "article = data[0].page_content\n",
    "\n",
    "map_reduce.run(input_text=article, question=\"What is the profession mentioned in the article?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47866b96-3127-4178-a01d-3b26a81b53ff",
   "metadata": {},
   "source": [
    "# Refine Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ed48dcd-709e-4291-8cc7-acd35d3cb6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Document loader\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(SCRAPE_URL)\n",
    "data = loader.load()\n",
    "\n",
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "# Since FAISS requires splits from text and not Lang Document type, we do the below\n",
    "all_splits = text_splitter.split_text(text=data[0].page_content)\n",
    "docs = [Document(page_content=t) for t in all_splits[:3]]\n",
    "\n",
    "refine_chain = load_summarize_chain(llm=llm, chain_type=\"refine\",return_refine_steps=True)\n",
    "\n",
    "# refine_chain.run(docs[0].page_content)\n",
    "resp = refine_chain({\"input_documents\": [Document(page_content=t) for t in all_splits[:15]]},return_only_outputs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "25a80b4f-714f-4787-b55d-7db064a5c07a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': [' The M����o����n����k���� Immigrant Who S����o����l����d���� Bought His Ferrari | by SparkIQ Tech | MediumThe Monk Who Sold His Ferrari tells the story of a lawyer who was forced to confront his spiritual crisis and out-of-balance life, and how he found redemption through selling his beloved Ferrari.',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " 'output_text': ''}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bdf046af-7bfc-4967-ac5c-beacbc0bd9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['A: Here\\'s your answer:\\n\\n\"The Monk Who Sold His Ferrari tells the story of Julian Mantle, a lawyer who is forced to confront the spiritual crisis of his out-of-balance (lively and rich) life, and the decision he makes to sell his beloved Ferrari in order to pursue a more meaningful existence.\"',\n",
       "  '',\n",
       "  ''],\n",
       " 'output_text': ''}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "refine_template = (\n",
    "    \"Your job is to produce a final summary\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary in Italian\"\n",
    "    \"If the context isn't useful, return the original summary.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"text\"],\n",
    "    template=refine_template,\n",
    ")\n",
    "chain = load_summarize_chain(llm=llm, chain_type=\"refine\", return_intermediate_steps=True, question_prompt=PROMPT, refine_prompt=refine_prompt)\n",
    "chain({\"input_documents\": docs}, return_only_outputs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
