{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d0025a1-136b-4bdd-b9a9-82cca0fb615a",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://python.langchain.com/docs/use_cases/question_answering/\n",
    "- https://gist.github.com/waleedkadous/aea1d312d68c9431949442cc562d5f2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ebf952e-16c1-4b76-b8e6-e26913d04c16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=10, micro=12, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970a61c-13f7-4996-a5fe-0b83fcae41af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install langchain==0.0.242\n",
    "!pip3 install chromadb==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c85d03a-34c6-4995-83cd-1e4824af21b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "SCRAPE_URL = \"https://medium.com/@symmetrics_hr/the-m%CC%B6o%CC%B6n%CC%B6k%CC%B6-immigrant-who-s%CC%B6o%CC%B6l%CC%B6d%CC%B6-bought-his-ferrari-e7be20c4d891\"\n",
    "DEFAULT_QUESTION = \"What is H1b?\"\n",
    "SAMPLE_PDF_DOCUMENT = \"Tech_Hubs_NOFO.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77091698-601e-4a52-82f2-7175c9395ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.base import Embeddings\n",
    "from typing import List\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class LocalHuggingFaceEmbeddings(Embeddings):\n",
    "    def __init__(self, model_id): \n",
    "        # Should use the GPU by default\n",
    "        self.model = SentenceTransformer(model_id)\n",
    "        \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Embed a list of documents using a locally running\n",
    "           Hugging Face Sentence Transformer model\n",
    "        Args:\n",
    "            texts: The list of texts to embed.\n",
    "        Returns:\n",
    "            List of embeddings, one for each text.\n",
    "        \"\"\"\n",
    "        embeddings =self.model.encode(texts)\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Embed a query using a locally running HF \n",
    "        Sentence trnsformer. \n",
    "        Args:\n",
    "            text: The text to embed.\n",
    "        Returns:\n",
    "            Embeddings for the text.\n",
    "        \"\"\"\n",
    "        embedding = self.model.encode(text)\n",
    "        return list(map(float, embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864a36c-d35e-45d8-8e13-93d7a5792042",
   "metadata": {},
   "source": [
    "### HuggingFace\n",
    "- For using transformers library to download models or interact with huggingface hub...\n",
    "- On a shell prompt `huggingface-cli login` - complete the process\n",
    "- Access token can be got using [help](https://huggingface.co/docs/hub/security-tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a0e26-eea6-4280-b8e5-8d2ccf26a924",
   "metadata": {},
   "source": [
    "# Implicit vectorstore\n",
    "- Default is Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79993bd0-277e-40f6-bd42-7a8d45cd7161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Document loader\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "loader = WebBaseLoader(SCRAPE_URL)\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c447194c-45fb-4b68-93a6-4281e0c64863",
   "metadata": {},
   "source": [
    "# Use GPT4All\n",
    "- OpenAI can be used as well, however we wanted everything local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee3b4e19-a1ad-41c9-8883-53d78266f816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 3200\n",
      "llama_model_load_internal: n_mult     = 240\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 26\n",
      "llama_model_load_internal: n_rot      = 100\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 8640\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 3B\n",
      "llama_model_load_internal: ggml ctx size =    0.06 MB\n",
      "llama_model_load_internal: mem required  = 2862.72 MB (+  682.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  650.00 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' H1B refers to a nonimmigrant visa classification used by U.S. employers to hire foreign workers in specialty occupations, such as in the fields of science, engineering, and technology.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "#from langchain.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "# from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "\n",
    "index = VectorstoreIndexCreator(embedding=HuggingFaceEmbeddings()).from_loaders([loader])\n",
    "\n",
    "# Question-answering\n",
    "question = DEFAULT_QUESTION\n",
    "llm = GPT4All(model=\"/home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\",max_tokens=2048)\n",
    "index.query(question, llm=llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e94c1-7c2f-46f1-ac47-c89ce95cbd92",
   "metadata": {},
   "source": [
    "## Explicit Chrome Store with QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6b3a4-9617-475d-ac33-e8a7a1f072e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Document loader\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(SCRAPE_URL)\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f1ad4-9a3f-433b-9db2-b00129e309d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538bc098-620c-4d6d-b887-41fe95db346d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store \n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"my_collection\")\n",
    "\n",
    "chroma_vector_store = Chroma.from_documents(documents=all_splits,\n",
    "                                            client=chroma_client,collection_name=\"my_collection\",\n",
    "                                    embedding=HuggingFaceEmbeddings(),persist_directory=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f914712f-b452-489e-9400-96fa827d4890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automobile aficionados, owning the brand of car that you dreamed since childhood can be the biggest achievement of life (until then).This article is about Venkat^[1], a Google Engineer who wished to buy his Ferrari before he reaches the age of 40H1b VisaIf you work in US tech sector, you donâ€™t need introduction to H1b. It is one of the most sought after visa (among many others) that is given to a worker with high skills (as defined by US government). Basically the united states government'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question-answering\n",
    "question = DEFAULT_QUESTION\n",
    "results = chroma_vector_store.similarity_search(query=question,k=4)\n",
    "results[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b139099-7d42-4b1c-b251-95dbd31269cf",
   "metadata": {},
   "source": [
    "### MMR\n",
    "- maximum marginal relevance search where it optimizes for similarity to query AND diversity among selected documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12f8c702-ab3b-4337-9ede-fb9d8c5aed12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automobile aficionados, owning the brand of car that you dreamed since childhood can be the biggest achievement of life (until then).This article is about Venkat^[1], a Google Engineer who wished to buy his Ferrari before he reaches the age of 40H1b VisaIf you work in US tech sector, you donâ€™t need introduction to H1b. It is one of the most sought after visa (among many others) that is given to a worker with high skills (as defined by US government). Basically the united states government'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question-answering\n",
    "question = DEFAULT_QUESTION\n",
    "results = chroma_vector_store.max_marginal_relevance_search(query=question,k=4)\n",
    "results[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6f72e-cd8a-40c8-8975-a63a8c4aa61f",
   "metadata": {},
   "source": [
    "## QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4224cf8-2cb1-48c2-9ce7-3548c4162857",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 3200\n",
      "llama_model_load_internal: n_mult     = 240\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 26\n",
      "llama_model_load_internal: n_rot      = 100\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 8640\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 3B\n",
      "llama_model_load_internal: ggml ctx size =    0.06 MB\n",
      "llama_model_load_internal: mem required  = 2862.72 MB (+  682.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  650.00 MB\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "\n",
    "llm = GPT4All(model=\"/home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\",max_tokens=2048)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "response = chain.run(input_documents=results,question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84f8f9b0-eca3-49c4-8822-356b714b253e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" H1b is a type of visa given to skilled workers from other countries who work in the US tech sector. It allows them to live and work in the country for up to six years, with the option to renew their visas multiple times. The program was established in 2000 as part of the government's efforts to attract and retain highly skilled workers.\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81925a1-52ce-43cc-ade5-1b4faf33c24a",
   "metadata": {},
   "source": [
    "# Use FAISS with QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3cde6-9424-40d3-9c29-3fb69e499ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Document loader\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(SCRAPE_URL)\n",
    "data = loader.load()\n",
    "\n",
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "# Since FAISS requires splits from text and not Lang Document type, we do the below\n",
    "all_splits = text_splitter.split_text(text=data[0].page_content)\n",
    "all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ee610e-9237-4bc6-bdba-afe455368e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FAISS stores in RAM\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings()\n",
    "embeddings = LocalHuggingFaceEmbeddings('multi-qa-mpnet-base-dot-v1')\n",
    "faiss_vector_store = FAISS.from_texts(all_splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396d375-cd10-43b7-afc3-f1d4ed4d1faf",
   "metadata": {},
   "source": [
    "## Embeddings created locally\n",
    "- When HuggingFaceEmbeddings() is called, a network calls happens\n",
    "- We can reduce this by locally creating the embeddings , hence LocalHuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1800066a-c420-4359-aa87-6aa4c1c00305",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automobile aficionados, owning the brand of car that you dreamed since childhood can be the biggest achievement of life (until then).This article is about Venkat^[1], a Google Engineer who wished to buy his Ferrari before he reaches the age of 40H1b VisaIf you work in US tech sector, you donâ€™t need introduction to H1b. It is one of the most sought after visa (among many others) that is given to a worker with high skills (as defined by US government). Basically the united states government'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question-answering\n",
    "question = DEFAULT_QUESTION\n",
    "results = faiss_vector_store.similarity_search(query=question,k=4)\n",
    "results[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2175611-0242-4e36-a413-2e1148bab835",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 3200\n",
      "llama_model_load_internal: n_mult     = 240\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 26\n",
      "llama_model_load_internal: n_rot      = 100\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 8640\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 3B\n",
      "llama_model_load_internal: ggml ctx size =    0.06 MB\n",
      "llama_model_load_internal: mem required  = 2862.72 MB (+  682.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  650.00 MB\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "\n",
    "llm = GPT4All(model=\"/home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\",max_tokens=2048)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "response = chain.run(input_documents=results,question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8fbb6355-cc98-48d9-bb38-33529895c0fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" H1b is a type of visa given to skilled workers from other countries who work in the US tech sector. It allows them to live and work in the country for up to six years, with the option to renew their visas multiple times. The program was established in 2000 as part of the government's efforts to attract and retain highly skilled workers.\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703185c-4ca8-4b2c-986c-558966000309",
   "metadata": {},
   "source": [
    "## Ask questions over lengthy documents\n",
    "- US Government funding program for AI etc.\n",
    "- https://www.eda.gov/sites/default/files/2023-05/Tech_Hubs_NOFO.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39f02fc7-f85f-4002-a27f-e09dbf4a4f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: PyPDF2==3.0.1 in /home/ubuntu/anaconda3/envs/py310/lib/python3.10/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install PyPDF2==3.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb2f5903-f10d-4636-ae08-decca398a352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f17b04-23ea-4261-8726-81b0c5d9ac15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "pdf_reader = PdfReader(SAMPLE_PDF_DOCUMENT)\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1500,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len\n",
    "        )\n",
    "# Since FAISS requires splits from text and not Lang Document type, we do the below\n",
    "all_splits = text_splitter.split_text(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9017095b-1b20-423f-afad-e26ca85525cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FAISS stores in RAM\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "faiss_vector_store = FAISS.from_texts(all_splits, embedding=HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30b3cb69-92cf-4567-8ace-74ca499946a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 The National Science Foundation is required to review and update this list annually. For the purposes of both \\nPhases 1 and 2 of the Tech Hubs Competition, EDA is relying on the initial list enacte d by Congress at 42 U.S.C. § \\n19107(c).   \\nPage 6 of 37 significant technological strength from the above list as opposed to more nascent or less resourced \\ntechnology area s. \\n \\nIllustrations of potential relationships among Key Technology Focus Areas (KFTAs) and a coalition’s \\nselected core technology areas  \\nNote that the Tech Hubs program is not intended to fund basic and fundamental research nor activities \\nintended to increase capacity to conduct such research ; the National Science Foundation and other \\nagencies fund such activities . Instead , the Tech Hubs program is intended to advance the capacities of \\nplaces to commercializ e, deploy,  and domestic ally manufactur e and d eliver these technologies. All \\nprojects funded under both phases of the Tech Hubs Program should increase the speed and \\neffective ness with which industry and other organizations  transition technologies upward from \\nTechnology Readiness Levels  six through nine.3  \\niii. What entities are eligible to apply for S trategy Development  Grants , Designation,  and \\nImplementation Grants ? \\nConsortia are eligible to apply for D esignation and for grants under both phases of the Tech Hubs \\nProgram . For purposes of this program, each consortium must  include at least one of each  of the'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question-answering\n",
    "question = \"What is tech hubs program?\"\n",
    "results = faiss_vector_store.similarity_search(query=question,k=4)\n",
    "results[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b277409-4c28-4c39-bba8-447e6bf58536",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 3200\n",
      "llama_model_load_internal: n_mult     = 240\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 26\n",
      "llama_model_load_internal: n_rot      = 100\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 8640\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 3B\n",
      "llama_model_load_internal: ggml ctx size =    0.06 MB\n",
      "llama_model_load_internal: mem required  = 2862.72 MB (+  682.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  650.00 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The Tech Hubs Program is a U.S. government competition that aims to identify regions where an investment can catalyze self-sustaining, globally-competitive regions over the next decade, with each focused on a key technology focus area. To achieve this goal and fulfill statutory direction, EDA will run this competition with a focus on geographic diversity and equity in two phases through two separate Notices of Funding Opportunity (NOFO). In this Phase 1 NOFO, EDA will fund Strategy Development Grants and will Designate certain regions as Regional Technology and Innovation Hubs (Tech Hubs) . Applicants to this Phase 1 NOFO must choose whether they are pursuing a Strategy Development Grant, a Tech Hub, or both.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "\n",
    "llm = GPT4All(model=\"/home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\",max_tokens=2048)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "response = chain.run(input_documents=results,question=question)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4e3957-8cca-4757-b0a1-4e8ce9a2d88e",
   "metadata": {},
   "source": [
    "# LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "44a798cc-eb6d-4139-a510-c8983d5c7ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 3200\n",
      "llama_model_load_internal: n_mult     = 240\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 26\n",
      "llama_model_load_internal: n_rot      = 100\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 8640\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 3B\n",
      "llama_model_load_internal: ggml ctx size =    0.06 MB\n",
      "llama_model_load_internal: mem required  = 2862.72 MB (+  682.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  650.00 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Document(page_content='Designation Grant, or both. For Strategy Development Grants, applicants must propose a plan for developing a strategy for their Tech Hub that addresses the key technology focus area of their region and demonstrates how the proposed activities will catalyze self-sustaining economic development in the region over the next decade. For Designation Grants, applicants must identify regions that meet the criteria for geographic diversity and equity in order to be designated as a Tech Hub . 16 See https://www.commerce.gov/issues/workforce -development .', metadata={})] Document(page_content='these regions. The Designated Tech Hubs will receive additional funding and support to implement their strategies over the next decade, including through Implementation Grants awarded in Phase 2 of the program. 17 See https://www.commerce.gov/funding -opportunities/regional-technology-innovation-hubs .', metadata={})] Document(page_content='The Tech Hubs Program is designed to meet the individual needs of a particular region and what it specifically needs to catalyze becoming a sustainable, globally competitive Tech Hub in its consortia’s selected core technology area. EDA expects workforce development activities\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "\n",
    "llm = GPT4All(model=\"/home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\",max_tokens=2048)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "# Chain\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run\n",
    "question = \"What is tech hubs program?\"\n",
    "docs = faiss_vector_store.similarity_search(question)\n",
    "result = llm_chain(docs)\n",
    "\n",
    "# Output\n",
    "result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce73a553-ec1f-4f58-be24-3476f7497e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 The National Science Foundation is required to review and update this list annually. For the purposes of both \\nPhases 1 and 2 of the Tech Hubs Competition, EDA is relying on the initial list enacte d by Congress at 42 U.S.C. § \\n19107(c).   \\nPage 6 of 37 significant technological strength from the above list as opposed to more nascent or less resourced \\ntechnology area s. \\n \\nIllustrations of potential relationships among Key Technology Focus Areas (KFTAs) and a coalition’s \\nselected core technology areas  \\nNote that the Tech Hubs program is not intended to fund basic and fundamental research nor activities \\nintended to increase capacity to conduct such research ; the National Science Foundation and other \\nagencies fund such activities . Instead , the Tech Hubs program is intended to advance the capacities of \\nplaces to commercializ e, deploy,  and domestic ally manufactur e and d eliver these technologies. All \\nprojects funded under both phases of the Tech Hubs Program should increase the speed and \\neffective ness with which industry and other organizations  transition technologies upward from \\nTechnology Readiness Levels  six through nine.3  \\niii. What entities are eligible to apply for S trategy Development  Grants , Designation,  and \\nImplementation Grants ? \\nConsortia are eligible to apply for D esignation and for grants under both phases of the Tech Hubs \\nProgram . For purposes of this program, each consortium must  include at least one of each  of the'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"docs\"][0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c9a9fb-5557-4731-8d71-5665632f1c1a",
   "metadata": {},
   "source": [
    "# Retrieval QA\n",
    "- The most abstracted one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "04e547a7-f73d-4a59-993a-39a0fd7d0e03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 3200\n",
      "llama_model_load_internal: n_mult     = 240\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 26\n",
      "llama_model_load_internal: n_rot      = 100\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 8640\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 3B\n",
      "llama_model_load_internal: ggml ctx size =    0.06 MB\n",
      "llama_model_load_internal: mem required  = 2862.72 MB (+  682.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  650.00 MB\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "llm = GPT4All(model=\"/home/ubuntu/Downloads/orca-mini-3b.ggmlv3.q4_0.bin\",max_tokens=2048)\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=faiss_vector_store.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n",
    "\n",
    "context = faiss_vector_store.similarity_search(question)\n",
    "\n",
    "response = qa_chain({\"context\":context,\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0a7122d5-8f90-433c-ab36-460020329e20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Tech Hubs Program is a U.S. Economic Development Administration competition that aims to support regions in becoming globally competitive by investing in modernization of manufacturing and innovation in key technology focus areas. It will fund two phases of regional development, with Phase 1 focused on strategy development grants and designating regions as tech hubs (Tech Hubs), and Phase 2 focused on implementation grants for the designated regions.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"result\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
